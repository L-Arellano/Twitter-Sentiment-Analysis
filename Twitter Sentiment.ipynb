{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab2d4f5-5404-42ff-b01f-81197247ba95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from textblob import TextBlob\n",
    "import tweepy\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7baca7a-90f9-48a4-91a2-38878628f5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace with your own Twitter API credentials\n",
    "consumer_key = \"\"\n",
    "consumer_secret = \"\"\n",
    "access_token = \"\"\n",
    "access_token_secret = \"\"\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "# List of hashtags\n",
    "hashtags = [\"\", \"\", \"\"]\n",
    "\n",
    "# List to store the tweets and set to store the ids\n",
    "all_tweets = []\n",
    "tweet_ids = set()\n",
    "\n",
    "# Get the list of stopwords in English\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "for hashtag in hashtags:\n",
    "    tweets = tweepy.Cursor(api.search, q=hashtag, lang='en', tweet_mode='extended').items(1000)\n",
    "    for tweet in tweets:\n",
    "        if tweet.id not in tweet_ids:\n",
    "            all_tweets.append(tweet)\n",
    "            tweet_ids.add(tweet.id)\n",
    "\n",
    "positive_tweets = []\n",
    "negative_tweets = []\n",
    "\n",
    "for tweet in all_tweets:\n",
    "    tweet_text = tweet.full_text\n",
    "    # Preprocessing\n",
    "    tweet_text = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', tweet_text, flags=re.MULTILINE)\n",
    "    tweet_text = re.sub(r'\\@\\w+|\\#','', tweet_text)\n",
    "    tweet_text = tweet_text.lower()\n",
    "\n",
    "    # Tokenize the tweet text and remove stopwords\n",
    "    word_tokens = word_tokenize(tweet_text)\n",
    "    filtered_sentence = [w for w in word_tokens if not w in stop_words]\n",
    "    filtered_sentence = ' '.join(filtered_sentence)\n",
    "\n",
    "    # Sentiment analysis\n",
    "    blob = TextBlob(filtered_sentence)\n",
    "    sentiment = blob.sentiment.polarity\n",
    "    if sentiment > 0:\n",
    "        positive_tweets.append(filtered_sentence)\n",
    "    elif sentiment < 0:\n",
    "        negative_tweets.append(filtered_sentence)\n",
    "\n",
    "# Getting most common words in positive tweets\n",
    "positive_counter = Counter(\" \".join(positive_tweets).split())\n",
    "common_positive_words = positive_counter.most_common(10)\n",
    "\n",
    "# Getting most common words in negative tweets\n",
    "negative_counter = Counter(\" \".join(negative_tweets).split())\n",
    "common_negative_words = negative_counter.most_common(10)\n",
    "\n",
    "print(\"Common words in positive tweets:\")\n",
    "for word, count in common_positive_words:\n",
    "    print(word, count)\n",
    "\n",
    "print(\"\\nCommon words in negative tweets:\")\n",
    "for word, count in common_negative_words:\n",
    "    print(word, count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
